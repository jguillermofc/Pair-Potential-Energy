{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **On the utilization of pair-potential energy functions in multi-objective optimization**\n",
    "\n",
    "---\n",
    "\n",
    "by Jesús Guillermo Falcón-Cardona<sup>a</sup>, Edgar Covantes Osuna<sup>a</sup>, Carlos A. Coello Coello<sup>b</sup>, and Hisao Ishibuchi<sup>c</sup>\n",
    "\n",
    "<sup>a</sup> Tecnológico de Monterrey, School of Engineering and Sciences, Av. Eugenio Garza Sada 2501 Sur, Col. Tecnológico, Monterrey, Nuevo León, México 64849.\n",
    "\n",
    "<sup>b</sup> CINVESTAV-IPN, Department of Computer Science, Av. IPN 2508, Col. San Pedro Zacatenco, México City, México 07360.\n",
    "\n",
    "<sup>c</sup> Southern University of Science and Technology, Department of Computer Science and Engineering, 1088 Xueyuan Avenue, Shenzhen, People's Republic of China,  518055\n",
    "\n",
    "This is a companion notebook for the paper titled with the same name. For readability, the present notebook can be considered as supplementary material for **Section 3.2.2 Predicting the optimal value of $\\alpha$**. Here we include runnable code (with some comments) and section titles. This notebook omits everything else in the paper.\n",
    "\n",
    "If a more detailed explanation is needed, we recommend reading the notebook side by side with a copy of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting $\\alpha$** $\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}$\n",
    "\n",
    "The pair-potential functions are commonly used to distribute points on a manifold (or discretizing a manifold). Given a $d$-dimensional manifold $\\mathcal{A}$ in the search space $\\mathbb{R}^m$ ($d \\le m$) with a given distribution $X$ and described by some geometric property or by some parametrization, the goal is to generate a large number of $N$ points in $\\mathcal{A}$ such that they are well-separated and have (nearly) distribution $X$. In other words, the aim is to \n",
    "generate the smallest population possible that describes the distribution of the full set of elements in $\\mathcal{A}$.\n",
    "\n",
    "These functions are of the form $\\mathcal{K}:\\mathbb{R}^m \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}$ that model the interaction between two given particles. \n",
    "The total energy $U$ of a system with $N$ particles is given as follows:\n",
    "\n",
    "\\begin{equation}\\label{eq:U}\n",
    "    U(\\mathcal{A}) = \\sum_{i = 1}^N \\sum_{\\begin{array}{c} j = 1 \\\\ j \\not = i \\end{array}}^N \\mathcal{K}\\left(\\vec{a}_i, \\vec{a}_j\\right),\n",
    "\\end{equation}\n",
    "where $\\mathcal{A} = \\{\\vec{a}_1, \\dots, \\vec{a}_N\\}$ is an approximation set, and $\\vec{a}_j \\in \\mathbb{R}^m, j=1, \\dots, N$.\n",
    "\n",
    "In the following, we describe the pair-potential functions which are of interest. For all cases, $\\vec{u} = \\vec{F}\\left(\\vec{x}\\right), \\vec{v}= \\vec{F}\\left(\\vec{y}\\right) \\in \\mathbb{R}^m$ and $\\norm{\\cdot}$ represents the Euclidean distance.\n",
    "\n",
    "**Riesz $\\alpha$-kernel**: Given a parameter $\\alpha > 0$, it is defined as follows:\n",
    "\\begin{equation}\\label{eq:RSE}\n",
    "    \\mathcal{K}^{\\text{RSE}}\\left(\\vec{u}, \\vec{v}\\right) = \\frac{1}{\\norm{\\vec{u} - \\vec{v}}^\\alpha}.\n",
    "\\end{equation}\n",
    "\n",
    "**Gaussian $\\alpha$-kernel**: Given a parameter $\\alpha > 0$, this pair-potential is defined in the following:\n",
    "\\begin{equation}\\label{eq:GAE}\n",
    "    \\mathcal{K}^{\\text{GAE}}\\left(\\vec{u}, \\vec{v}\\right) = e^{-\\alpha\\norm{\\vec{u} - \\vec{v}}^2}.\n",
    "\\end{equation}\n",
    "\n",
    "**Pöschl-Teller kernel**: Given $V_1, V_2, \\alpha > 0$, it is given by:\n",
    "\\begin{equation}\\label{eq:PT}\n",
    "    \\mathcal{K}^{\\text{PTP}}\\left(\\vec{u}, \\vec{v}\\right) = \\frac{V_1}{\\sin^2 \\left( \\alpha\\norm{ \\vec{u} - \\vec{v}}\\right)} + \\frac{V_2}{\\cos^2 \\left( \\alpha\\norm{ \\vec{u} - \\vec{v}}\\right)}.\n",
    "\\end{equation}\n",
    "\n",
    "**Modified Pöschl-Teller kernel**: Given $D, \\alpha > 0$, this function is as follows:\n",
    "\\begin{equation}\\label{eq:MPT}\n",
    "    \\mathcal{K}^{\\text{MPT}}\\left(\\vec{u}, \\vec{v}\\right) = -\\frac{D}{\\cosh^2 \\left(\\alpha \\norm{\\vec{u} - \\vec{v}}\\right)}.\n",
    "\\end{equation}\n",
    "\n",
    "**Kratzer kernel**: Given $V_1, V_2, \\alpha > 0$, the Kratzer potential is given as follows:\n",
    "\\begin{equation}\\label{eq:KRA}\n",
    "    \\mathcal{K}^{\\text{KRA}}\\left(\\vec{u}, \\vec{v}\\right) = V_1 \\left ( \\frac{\\norm{\\vec{u} - \\vec{v}} - 1/\\alpha}{\\norm{\\vec{u} - \\vec{v}}} \\right )^2 + V_2.\n",
    "\\end{equation}\n",
    "\n",
    "**Coulomb kernel**: it is given by:\n",
    "\\begin{equation}\\label{eq:COU}\n",
    "    \\mathcal{K}^\\text{COU}\\left(\\vec{u}, \\vec{v}\\right) = \\frac{q_1q_2}{4\\pi\\epsilon_0} \\cdot \\frac{1}{\\norm{\\vec{u} - \\vec{v}}^2},\n",
    "\\end{equation}\n",
    "where we set $q_1 = \\sqrt{\\sum_{i=1}^{m}u_i^2}$ and $q_2 = \\sqrt{\\sum_{i=1}^{m}v_i^2}$, and $\\frac{1}{4\\pi\\epsilon_0}$ is the Coulomb's constant. \n",
    "\n",
    "As can be seen, excluding the Coulomb's law function, all other functions require the definition of a parameter $\\alpha$. By replacing each one of the six previous kernels in the total energy $U$ equation, we define an equal number of pair-potential energy functions, denoted as $$$U^{\\text{RSE}}$, $U^{\\text{GAE}}$, $U^{\\text{MPT}}$, $U^{\\text{PTP}}$, $U^{\\text{KRA}}$, and $U^{\\text{COU}}$.\n",
    "\n",
    "In [1], it was shown that the approximation sets generated by an RSE-based archive strongly depends on the value of the parameter $\\alpha$ (see Riesz $\\alpha$-kernel). This behavior was also pointed out in [2] for $\\mathcal{K}^{\\text{GAE}}$, $\\mathcal{K}^{\\text{MPT}}$, $\\mathcal{K}^{\\text{PTP}}$, and $\\mathcal{K}^{\\text{KRA}}$.  Hence, an open question is how to set $\\alpha$ and other parameter values to generate an $N$-point approximation to $\\mathcal{A}^*$ that represents the underlying manifold regardless of its geometry and dimension, exhibiting good diversity.\n",
    "\n",
    "The $\\alpha$ parameter is the most critical one in our study since it controls the rate of decrease of the kernels. Hence, it directly influences the overall pair-potential energy of the Pareto front approximation which impacts its diversity. In this notebook, we aim to determine how to set $\\alpha$ to generate the Pareto front approximations that adequately represent the underlying manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**\n",
    "\n",
    "Although Python 2.x may work, it is deprecated so we strongly recommend to use Python 3 instead. Also, we strongly recommend to use `tensorflow` 2 as well as `sklearn` $\\ge 0.20$. Next we define a few common modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.8 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 8)\n",
    "\n",
    "# Tensorflow ≥2.3 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.3\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "# Scikit-Learn >=0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "# To plot figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inputs and Outputs**\n",
    "\n",
    "Before we start it is necessary to define some paths regarding the location of the dataset and files generated as outputs from the current notebook. If you downloaded the proyect from git, you should not have problems running the following code but if you modify the folder and archives location make sure to assign the proper location and name to the corresponding element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root name of the dataset location.\n",
    "DATASET_ROOT_DIR = 'datasets'\n",
    "\n",
    "# Name of the folder containing all datasets generated with the newton-based approximation method.\n",
    "NEWTON = 'newtonParams'\n",
    "\n",
    "# Name of the folder containing all datasets generated with the genetic-based approximation method.\n",
    "GENETIC = 'geneticParams'\n",
    "\n",
    "# Name of the output directory where all resulting files of the present work will be stored.\n",
    "OUTPUT_DIR = 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Description of the dataset**\n",
    "\n",
    "For the case of the Newton-based approximation method, two datasets were created for the functions $\\mathcal{K}^{\\text{GAE}}$ and $\\mathcal{K}^{\\text{MPT}}$; for the Genetic-based approximation method, five datasets for the functions $\\mathcal{K}^{\\text{GAE}}$, $\\mathcal{K}^{\\text{KRA}}$, $\\mathcal{K}^{\\text{MPT}}$, $\\mathcal{K}^{\\text{PTP}}$, and $\\mathcal{K}^{\\text{RSE}}$ were created for a total of 7 datasets, each with 504 instances and stored in comma-separated values (CSV) files.\n",
    "\n",
    "Each of the 7 datasets contains 1 categorical, 2 numerical _features_, and 1 numerical _target_. For the categorical feature, we have considered the _geometry_, which describes the shape of the Pareto front (linear, concave, degenerate, disconnected, or mixed). For the numerical features, we have considered the  _dimension_, describing the number of objectives: $\\{2, 3, 4, 5, 6, 7, 8, 9, 10\\}$, and _cardinality_, that describes the number of points of a given approximation set $\\mathcal{A}$: $\\{25, 50, 75, 100, 150, 200, 250, 300\\}$. Finally, for the case of the _target_, we have defined the parameter $\\alpha\\in \\mathbb{R}^{+}$ used in all pair-potential functions metioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we are using as an example the dataset created for the GAE function using the newton-based approximation method.\n",
    "df = pd.read_csv(os.path.join(DATASET_ROOT_DIR, NEWTON, 'GAE.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each dataset contains different kind of features (1 categorical and 2 numerical with different ranges), the text in feature _geometry_ was converted into a numerical value, then, feature-wise normalization was performed: for each feature in the input data (a column in the input data matrix) was normalized using _Min-Max scaling_ and _Standardization_.\n",
    "\n",
    "In Min-Max scaling, values are shifted and rescaled so that they end up ranging from 0 to 1. This is performed by subtracting the min value and dividing by the max minus the min. Standardization subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance. Min-Max was selected due to its well-known use in machine learning, and standardization was chosen since it is much less affected by outliers, and for comparison reasons with Min-Max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for each of the previous experimental setups (raw data, feature scaling with Min-Max and feature scaling with standardization) K-fold cross validation was introduced to validate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plot and pre-processing**\n",
    "\n",
    "In the following some auxiliary functions are defined. The first function is used to plot the results from different metrics such as _Minimum Squared error_ `mse` for loss calculation:\n",
    "\\begin{equation}\n",
    "\\mathrm{MSE}\\left(\\mathbf{X}, h\\right)=\\frac{1}{m}\\sum_{i=1}^{m}\\left(h\\left(\\mathbf{x}^{(i)}\\right)-y^{(i)}\\right)^2,\n",
    "\\end{equation}\n",
    "where $m$ is the number of instances in the dataset, $\\mathbf{x}^{(i)}$ is a vector of all the feature values (excluding the target) of the $i$-th instance in the dataset, and $y^{(i)}$ is its target (the desired output value for that instance). $\\mathbf{X}$ is a matrix containing all the feature values (excluding targets) of all instances in the dataset. There is one row per instance, and the $i$-th row is equal to the transpose of $\\mathbf{x}^{(i)}$, noted $\\left(\\mathbf{x}^{(i)}\\right)^{\\text{T}}$. $h$ is the system's prediction function, also called a _hypothesis_. When the system is given an instance's feature vector $\\mathbf{x}^{(i)}$, it outputs a predicted value $\\hat{y}^{(i)}=h(\\mathbf{x}^{(i)})$ for that instance. Then, $\\mathrm{MSE}(\\mathbf{X}, h)$ is the loss function measured on the set of examples using the _hypothesis_ $h$.\n",
    "\n",
    "To measure the performance we considered the _Mean absolute error_ `mae`, to measure the distance between the vector of predictions and the vector of target values:\n",
    "\\begin{equation}\n",
    "\\mathrm{MAE}\\left(\\mathbf{X}, h\\right)=\\frac{1}{m}\\sum_{i=1}^{m}\\left|h\\left(\\mathbf{x}^{(i)}\\right)-y^{(i)}\\right|.\n",
    "\\end{equation}\n",
    "\n",
    "Also, we make use of the _R-Squared score_ (`r_square` or the coefficient of determination). This metric represents the proportion of variance (of $y$) that has been explained by the independent variables of the system. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.\n",
    "\n",
    "As such, variance is dataset dependent, $\\mathrm{R}^2$ may not be meaningfully comparable across different datasets. The best possible score is, $1.0$ and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of $y$, disregarding the input features, would get a $\\mathrm{R}^2$ score of $0.0$.\n",
    "\n",
    "If $h\\left(\\mathbf{x}^{(i)}\\right)$ is the predicted value of the $i$-th sample and $y^{(i)}$ is the corresponding true value for total $m$ samples, the estimated $\\mathrm{R}^2$ is defined as\n",
    "\\begin{equation}\n",
    "\\mathrm{R}^2\\left(\\mathbf{X}, h\\right)=1-\\frac{\\displaystyle\\sum_{i=1}^{m}\\left(h\\left(\\mathbf{x}^{(i)}\\right)-y^{(i)}\\right)^2}{\\displaystyle\\sum_{i=1}^{m}\\left(y^{(i)}-\\bar{y}\\right)^2},\n",
    "\\end{equation}\n",
    "where $\\bar{y}=\\frac{1}{n}\\sum_{i=1}^{m}y^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    '''\n",
    "    This function plots in a grid 1x3 the results obtanied from the metrics `mse`, `mae`, and `r_square` \n",
    "    during the training and validation process.\n",
    "    \n",
    "    Args:\n",
    "        history (History object): a History object that contains a member `history`, which is a dictionary \n",
    "                                  containing the data about everything that happened during training \n",
    "                                  and validation.\n",
    "    Returns:\n",
    "        No Value.\n",
    "    '''\n",
    "    \n",
    "    plt.clf()\n",
    "    mse = history.history['loss']\n",
    "    val_mse = history.history['val_loss']\n",
    "    mae = history.history['mae']\n",
    "    val_mae = history.history['val_mae']\n",
    "    r_square_m = history.history['r_square']\n",
    "    val_r_square_m = history.history['val_r_square']\n",
    "    \n",
    "    epochs = range(1, len(mse) + 1)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,4), constrained_layout = True)\n",
    "    \n",
    "    fig.suptitle('Metrics for the training and validation sets', y=-0.1)\n",
    "    \n",
    "    ax1.plot(epochs, mse, 'r', label='Training loss')\n",
    "    ax1.plot(epochs, val_mse, 'b', label='Validation loss')\n",
    "    ax1.set_title('Training and validation loss', y=-0.25)\n",
    "    ax1.set(xlabel='Epochs', ylabel='Loss (mse)')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(epochs, mae, 'r', label='Training mae')\n",
    "    ax2.plot(epochs, val_mae, 'b', label='Validation mae')\n",
    "    ax2.set_title('Training and validation mae', y=-0.25)\n",
    "    ax2.set(xlabel='Epochs', ylabel='Accuracy (mae)')\n",
    "    ax2.legend()\n",
    "\n",
    "    ax3.plot(epochs, r_square_m, 'r', label='Training r square')\n",
    "    ax3.plot(epochs, val_r_square_m, 'b', label='Validation r square')\n",
    "    ax3.set_title('Training and validation r square', y=-0.25)\n",
    "    ax3.set(xlabel='Epochs', ylabel='R square')\n",
    "    ax3.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we show the functions used for loading and processing all functions datasets in .csv format for training, validation and prediction using `keras`. The second function calculates the `r_square` score. \n",
    "\n",
    "Since each of the seven datasets used are small (504 instances each), the last function performs _K-fold cross-validation_ to ensure the reliability of results. This methodology was applied using 10 partitions to estimate the performance of the model, and also to measure how precise this estimate is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary is used as one-hot encoding in which a unique integer index is associated with every geometry in the datasets.\n",
    "GEOMETRY = {'degenerate': 1, 'disconnected': 2, 'linear': 3, 'concave': 4, 'mixed': 5, 'convex': 6}\n",
    "\n",
    "def get_datasets_csv_reader(dir_path, training_size = 0.8, shuffle=True, norm=None):\n",
    "    '''\n",
    "    Reads a .csv file and creates the training and testing sets.\n",
    "    \n",
    "    Args:\n",
    "        dir_path (str): path of the source .csv file.\n",
    "        training_size (float): Percentage of instances that will belong to the training set. Default: 0.8.\n",
    "        shuffle (bool): Whether to shuffle the data or not. Default: True.\n",
    "        norm (str): Whether to normilize the data or not. Options: min_max or std. Default: None.\n",
    "        \n",
    "    Returns:\n",
    "        train_data (numpy ndarray, float32): Matrix containing instances for training (training set).\n",
    "        train_targets (numpy ndarray, float64): Array containing all true target values of the training set.\n",
    "        test_data (numpy ndarray, float32): Matrix containing instances for testing (testing set).\n",
    "        test_targets (numpy ndarray, float64): Array containing all true target values of the testing set.\n",
    "    '''\n",
    "    df = pd.read_csv(dir_path)\n",
    "    df = df.replace({'geometry': GEOMETRY})\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "    targets = df[' alpha'].to_numpy()\n",
    "    df.drop(' alpha', axis='columns', inplace=True)\n",
    "    data = np.asarray(df.values).astype('float32')\n",
    "    \n",
    "    if norm is not None:\n",
    "        if norm == 'min_max':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif norm == 'std':\n",
    "            scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "    \n",
    "    train_size = int(len(data) * training_size)\n",
    "\n",
    "    train_data = data[:train_size]\n",
    "    train_targets = targets[:train_size]\n",
    "\n",
    "    test_data = data[train_size:]\n",
    "    test_targets = targets[train_size:]\n",
    "    \n",
    "    return train_data, train_targets, test_data, test_targets\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    '''\n",
    "    Calculates the `r_square` score.\n",
    "    \n",
    "    Args:\n",
    "        y_true (Tensor, float32): True values of the instances.\n",
    "        y_pred (Tensor, float32): Predicted values of the instances.\n",
    "    \n",
    "    Returns:\n",
    "        r_square_score (Tensor, float32): `r_square` score \n",
    "    '''\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    r_square_score = 1 - (SS_res/SS_tot)\n",
    "    return r_square_score\n",
    "\n",
    "# This dictionary is used to define the dependencies required by model when loaded as .h5 file.\n",
    "dependencies = {'r_square': r_square}\n",
    "\n",
    "def perform_Kfold(train_data, train_targets, splits=10, shuffle=True, callbacks_list=None):\n",
    "    '''\n",
    "    Performs K-fold cross-validation on the trainig data set.\n",
    "    \n",
    "    Args:\n",
    "        train_data (numpy ndarray, float32): Matrix containing instances for training (training set).\n",
    "        train_targets (numpy ndarray, float64): Array containing all true target values of the training set.\n",
    "        splits (int): Number of folds.\n",
    "        shuffle (bool): Whether to shuffle the data or not. Default: True.\n",
    "        callbacks_list (list, callbacks objects): A list of Keras callback objects.\n",
    "        \n",
    "    Returns:\n",
    "        validation_mae_scores (list(list), float): A list of list with float numbers of the validation `mae` scores.\n",
    "    '''\n",
    "    skfolds = KFold(n_splits=splits, shuffle=shuffle, random_state=42)\n",
    "\n",
    "    validation_mae_scores = []\n",
    "\n",
    "    for train_index, valid_index in skfolds.split(train_data, train_targets):\n",
    "        X_train = train_data[train_index]\n",
    "        y_train = train_targets[train_index]\n",
    "    \n",
    "        X_valid = train_data[valid_index]\n",
    "        y_valid = train_targets[valid_index]\n",
    "    \n",
    "        model = build_model()\n",
    "    \n",
    "        history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs = 200,\n",
    "                            verbose = 2,\n",
    "                            callbacks = callbacks_list,\n",
    "                            validation_data = (X_valid, y_valid))\n",
    "    \n",
    "        history_dict = history.history\n",
    "    \n",
    "        validation_mae_scores.append(history_dict['val_mae'])\n",
    "    \n",
    "    return validation_mae_scores\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['Aprox. Method', 'Function', 'K-Fold', 'Norm', 'MSE', 'MAE', 'R_square'])\n",
    "predictions_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DNN Model**\n",
    "\n",
    "For this work, we use a _deep neural network_ (DNN) for regression. Our network consists of a sequence of densely connected layers (also called _fully connected_ neural layers). We employ a basic structure to explore the performance of the DNN for regression of the $\\alpha$ parameter in the pair-potential functions. The model comprises four Dense layers and three Dropout layers. As a default configuration, the first Dense layer has $1024$ neurons, the second and third have $512$ neurons, with ReLU activation each. All Dropout layers are defined with _dropout rate_ equal to $0.5$. The model uses an `adam` optimizer, `mse` as loss function, `mae` and `r_square` as metrics. The last part of the model contains a Dense layer with a single output neuron (its output is the predicted value) with no activation.\n",
    "\n",
    "The instances for each dataset were divided (uniformly at random) into training and testing set, as $80\\%$ and $20\\%$, respectively. Furthermore, $20\\%$ of the instances of the training set were selected (uniformly at random) to form part of the validation set. Then, the model was trained for $200$ epochs, $46$ instances at a time (batch size), and the best performing models for each dataset were selected for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    This function creates and compile the DNN model with a sequence of `Dense` and `Dropout` layers.\n",
    "    \n",
    "    Args:\n",
    "        None.\n",
    "    Return:\n",
    "        model (keras sequential model): A Model object with the grouped layers with training and inference features. \n",
    "    '''\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1024, activation='relu', input_shape=(3,)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae', r_square])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**, the following lines assume that you have the graphviz graph library and the Python interface installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file=os.path.join(OUTPUT_DIR, 'DNN_model_plot.png'), show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we train the DNN model using the datasets generated using the approximation methods. Each of the following datasets were used with no scaling method, followed by K-fold cross validation. Then, using two well-known scaling methods, the Standardization and MIN-MAX, each followed by K-fold cross validation. This to observe the effect of normalization in the current data.\n",
    "\n",
    "\n",
    "So, all training and experimentation will have the following structure. For each approximation method and function, the following training and validation is performed: \n",
    "- Approximation Method:\n",
    "     - Function with no normalization.\n",
    "     - Function with no normalization and K-fold.\n",
    "     - Function using standarization.\n",
    "     - Function using standarization and K-fold.\n",
    "     - Function using Min-Max.\n",
    "     - Function using Min-Max and K-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Newton-based approximation method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gaussian $\\alpha$-energy (GAE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gae_dir = os.path.join(DATASET_ROOT_DIR, NEWTON, 'GAE.csv')\n",
    "\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(gae_dir)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Newton', 'GAE', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Newton_GAE_model.h5'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Newton_GAE_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Newton_GAE_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Newton', 'GAE', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row\n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Newton', 'GAE', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Newton_GAE_STD_model.h5'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Newton_GAE_KFold_model_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Newton_GAE_KFold_model_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Newton', 'GAE', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row  \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Newton', 'GAE', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Newton_GAE_Min_Max_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Newton_GAE_KFold_model_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Newton_GAE_KFold_model_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Newton', 'GAE', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modified Pöschl-Teller Potential (MPT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpt_dir = os.path.join(DATASET_ROOT_DIR, NEWTON, 'MPT.csv')\n",
    "\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(mpt_dir)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Newton', 'MPT', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Newton_MPT_model.h5'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Newton_MPT_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Newton_MPT_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Newton', 'MPT', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row\n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Newton', 'MPT', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Newton_MPT_STD_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Newton_MPT_KFold_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Newton_MPT_KFold_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Newton', 'MPT', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Newton', 'MPT', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Newton_MPT_MIN_MAX_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Newton_MPT_KFold_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Newton_MPT_KFold_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Newton', 'MPT', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Geneti-based approximation method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gaussian $\\alpha$-energy (GAE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gae_dir = os.path.join(DATASET_ROOT_DIR, GENETIC, 'GAE.csv')\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(gae_dir)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'GAE', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_GAE_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_GAE_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_GAE_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'GAE', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'GAE', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_GAE_STD_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_GAE_KFold_model_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_GAE_KFold_model_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'GAE', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'GAE', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_GAE_model_MIN_MAX.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_GAE_KFold_model_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_GAE_KFold_model_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'GAE', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Kratzer Potential (KRA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kra_dir = os.path.join(DATASET_ROOT_DIR, GENETIC, 'KRA.csv')\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(kra_dir)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'KRA', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_KRA_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_KRA_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_KRA_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'KRA', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'KRA', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_KRA_STD_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_KRA_KFold_model_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_KRA_KFold_model_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'KRA', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'KRA', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_KRA_MIN_MAX_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_KRA_KFold_model_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_KRA_KFold_model_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'KRA', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modified Pöschl-Teller Potential (MPT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpt_dir = os.path.join(DATASET_ROOT_DIR, GENETIC, 'MPT.csv')\n",
    "\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(mpt_dir)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'MPT', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_MPT_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_MPT_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_MPT_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'MPT', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'MPT', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_MPT_STD_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_MPT_KFold_model_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_MPT_KFold_model_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'MPT', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'MPT', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_MPT_MIN_MAX_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_MPT_KFold_model_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_MPT_KFold_model_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'MPT', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pöschl-Teller Potential (PTP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptp_dir = os.path.join(DATASET_ROOT_DIR, GENETIC, 'PTP.csv')\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(ptp_dir)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'PTP', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_PTP_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_PTP_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_PTP_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'PTP', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'PTP', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_PTP_STD_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_PTP_KFold_model_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_PTP_KFold_model_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'PTP', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'PTP', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_PTP_MIN_MAX_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_PTP_KFold_model_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_PTP_KFold_model_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'PTP', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Riesz $s$-energy (RSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rse_dir = os.path.join(DATASET_ROOT_DIR, GENETIC, 'RSE.csv')\n",
    "train_data, train_targets, test_data, test_targets = get_datasets_csv_reader(rse_dir)\n",
    "\n",
    "model = build_model()\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'RSE', 'No', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_RSE_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_RSE_KFold_model.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_RSE_KFold_model.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'RSE', 'Yes', 'No']\n",
    "row.extend(model.evaluate(test_data, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row       \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'RSE', 'No', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_RSE_STD_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_RSE_KFold_model_std.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_RSE_KFold_model_std.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'RSE', 'Yes', 'STD']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Min-Max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(train_data_scaled, train_targets, epochs=200, batch_size=46, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['Genetic', 'RSE', 'No', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_DIR, 'Genetic_RSE_MIN_MAX_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best model found from all possible k-folds\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath = os.path.join(OUTPUT_DIR, 'Genetic_RSE_KFold_model_min_max.h5'),\n",
    "                    monitor = 'val_mae',\n",
    "                    save_best_only = True,\n",
    "                    mode = 'min')\n",
    "]\n",
    "\n",
    "validation_mae_scores = perform_Kfold(train_data_scaled, train_targets, callbacks_list=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mae_score = np.average(validation_mae_scores)\n",
    "\n",
    "model = load_model(os.path.join(OUTPUT_DIR, 'Genetic_RSE_KFold_model_min_max.h5'), custom_objects=dependencies)\n",
    "\n",
    "row = ['Genetic', 'RSE', 'Yes', 'MIN_MAX']\n",
    "row.extend(model.evaluate(test_data_scaled, test_targets))\n",
    "metrics_df.loc[len(metrics_df.index)] = row      \n",
    "validation_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusions**\n",
    "\n",
    "Overall, Figures 1 and 2 show that the regression models are able to produce $\\alpha$ values that promote well-diversified sets. This behavior is supported by Figure 3 that shows some Pareto front approximations based on $\\alpha$ values produced by the five regression models. The Pareto front approximations correspond to 100-point discretizations of three Irregular MOPs (IMOPs) [3] were not used to train the models. Despite the irregularity of the Pareto front shapes of these MOPs, the regression models generate $\\alpha$ values that promote high diversity. In consequence, instead of recommending fixed values of $\\alpha$ as in [2], we propose these regression models to be queried about $\\alpha$ values for different applications in multi-objective optimization.\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "<thead>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <figure>\n",
    "                <img src=\"figures/100_RSE.png\" style=\"width:100%\">\n",
    "                <figcaption>Figure 1: PD and SPD landscapes for $\\alpha$ sampled at $2^t, t\\in\\{-4-3,\\dots,18\\}$, using the RSE kernel. We show plots for 3, 5, and 10-objective DTLZ1, DTLZ2, WFG1, and WFG2 problems. The different markers are related to PD and SPD values using the Newton- and genetic-based $\\alpha$ approximations, their corresponding prediction models, and the fixed $\\alpha$ values recommended in [2]. All plots correspond to 100-point Pareto front approximations.</figcaption>\n",
    "            </figure>\n",
    "       </th>\n",
    "       <th>\n",
    "           <figure>\n",
    "                <img src=\"figures/100_GAE.png\" style=\"width:100%\">\n",
    "                <figcaption>Figure 2: PD and SPD landscapes for $\\alpha$ sampled at $2^t, t\\in\\{-4-3,\\dots,18\\}$, using the GAE kernel. We show plots for 3, 5, and 10-objective DTLZ1, DTLZ2, WFG1, and WFG2 problems. The different markers are related to PD and SPD values using the Newton- and genetic-based $\\alpha$ approximations, their corresponding prediction models, and the fixed $\\alpha$ values recommended in [2]. All plots correspond to 100-point Pareto front approximations.</figcaption>\n",
    "            </figure>\n",
    "        </th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "    <tr>\n",
    "        <th style=\"text-align:center\" colspan=\"2\"> \n",
    "            <figure>\n",
    "                <img src=\"figures/predictor_unknown.png\" style=\"width:100%\">\n",
    "                <figcaption>Figure 3: 100-point Pareto front approximations, for the IMOP5, IMOP6, and IMOP7 problems, generated by the regression models: $h_\\text{RSE}$, $h_\\text{PTP}$, $h_\\text{KRA}$, \n",
    "$h_\\text{GAE}$, and $h_\\text{MPT}$.</figcaption>\n",
    "            </figure>\n",
    "       </th>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **References**\n",
    "\n",
    "[1] J. G. Falcón-Cardona, H. Ishibuchi, C. A. Coello Coello, Riesz $s$-energy-based Reference Sets for Multi-Objective optimization, in: 2020 IEEE Congress on Evolutionary Computation (CEC), 2020, pp. 1-8. doi: https://doi.org/10.1109/CEC48606.2020.9185833\n",
    "\n",
    "[2] J. G. Falcón-Cardona, E. Covantes Osuna, C. A. Coello Coello, An Overview of Pair-Potential Functions for Multi-objective Optimization, in: Evolutionary Multi-Criterion Optimization (EMO 2021), Vol. 12654 of Lecture Notes in Computer Science, Springer International Publishing, 2021, pp. 401-412. doi: https://doi.org/10.1007/978-3-030-72062-9_32\n",
    "\n",
    "[3] Y. Tian, R. Cheng, X. Zhang, M. Li, Y. Jin, Diversity Assessment of Multi-Objective Evolutionary Algorithms: Performance Metric and Benchmark Problems, IEEE Computational Intelligence Magazine 14 (3) (2019) 61-74."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
